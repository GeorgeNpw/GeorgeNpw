<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[死锁]]></title>
    <url>%2F2019%2F05%2F15%2F%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁产生原因死锁是指两个或者两个以上的进程在执行过程中，因抢夺资源而造成的一种互相等待的现象，若无外力干涉它们将都无法推进下去。 如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性也就很低，否则就会因争夺有限的资源而陷入死锁。 死锁代码1234567891011121314151617181920212223242526272829303132public class DeadLockDemo &#123; public static void main(String[] args)&#123; String lockA = "lockA"; String lockB = "lockB"; new Thread(new HoldLockThread(lockA,lockB),"ThreadAAA").start(); new Thread(new HoldLockThread(lockB,lockA),"ThreadBBB").start(); &#125;&#125;class HoldLockThread implements Runnable&#123; private String lockA; private String lockB; public HoldLockThread(String lockA,String lockB)&#123; this.lockA = lockA; this.lockB = lockB; &#125; @Override public void run()&#123; synchronized (lockA)&#123; System.out.println(Thread.currentThread().getName()+"\t自己持有："+lockA+"\t尝试获得："+lockB); //暂停一下 try&#123; TimeUnit.SECONDS.sleep(2); &#125;catch (InterruptedException e)&#123;e.printStackTrace();&#125; synchronized (lockB)&#123; System.out.println(Thread.currentThread().getName()+"\t自己持有："+lockB+"\t尝试获得："+lockA); &#125; &#125; &#125;&#125; 如何查找定位 linux环境下 使用 ps -ef|grep xxxx ls -l 查看当前进程的命令 windows下的java运行程序，也有类似ps的查看进程的命令：jps -l 命令定位进程号；jstack xxxx(进程号)命令找到死锁查看]]></content>
      <categories>
        <category>死锁</category>
      </categories>
      <tags>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池]]></title>
    <url>%2F2019%2F05%2F15%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[线程池之前我们在使用多线程都是用Thread的start()来创建启动一个线程，但是在实际开发中，如果每个请求到达就创建一个新线程，开销是相当大的。服务器在创建和销毁线程上花费的时间和消耗的系统资源都相当大，甚至可能要比在处理实际的用请求的时间和资源要多的多。除了创建和销毁线程的开销之外，活动的线程也需要消耗系统资源。如果在一个 jvm 里创建太多的线程，可能会使系统由于过度消耗内存或“切换过度”而导致系统资源不足。这就引入了线程池概念。（第4种获得/使用java多线程的方式）线程池的主要特点是：线程复用，控制最大并发数，管理线程。 线程池的优势在java.util.concurrent包下，提供了一系列与线程池相关的类。合理的使用线程池，可以带来多个好处： 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 如何使用线程池 1、创建线程池 2、创建任务 3、执行任务 4、关闭线程池 五种线程池的使用场景 newSingleThreadExecutor ：一个单线程的线程池，可以用于需要保证顺序执行的场景，并且只有一个线程在执行。 newFixedThreadPool ：一个固定大小的线程池，可以用于已知并发压力的情况下，对线程数做限制。 newCachedThreadPool ：一个可以无限扩大的线程池，比较适合处理执行时间比较小的任务。 newScheduledThreadPool ：一个可以延时启动，定时启动的线程池，适用于需要多个后台线程执行周期任务的场景。 newWorkStealingPool ：一个拥有多个任务队列的线程池，可以减少连接数，创建当前可用cpu数量的线程来并行执行。 创建线程池1234567ExecutorService threadPool = new ThreadPoolExecutor(2, 5, 1L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardPolicy()); 线程池不允许用Executors来创建，而是通过ThreadPoolExecutor这样的方式，这样的处理方式可以让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明： Executors返回的线程池对象弊端如下： FixedThreadPool 和 SingleThreadExecutor：允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，导致OOM。 CachedThreadPool 和 ScheduledThreadPool：允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，导致OOM。 线程池的七大参数1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) ; corePoolSize ：线程池中常驻的核心线程数，决定着新提交的任务是新开线程去执行还是放到任务队列中，也是线程池的最最核心的参数。一般线程池开始时是没有线程的，只有当任务来了并且线程数量小于corePoolSize才会创建线程。 maximumPoolSize ：最大线程数，线程池能创建的最大线程数量。 keepAliveTime ：在线程数量超过corePoolSize后，多余空闲线程的最大存活时间。 unit ：keepAliveTime时间单位 workQueue ：存放来不及处理的任务的队列，是一个BlockingQueue。 threadFactory ：生产线程的工厂类，可以定义线程名，优先级等。 12ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat("demo-pool-%d").build(); handler ：拒绝策略，当前队列满且工作线程数大于或等于maximumPoolSize时启用，共4种策略。 4种拒绝策略 AbortPolicy ：当任务添加到线程池中被拒绝时，它将抛出 RejectedExecutionException 异常。 CallerRunsPolicy ： 当任务添加到线程池中被拒绝时，将任务回退给调用者。 DiscardOldestPolicy ：当任务添加到线程池中被拒绝时，线程池会放弃等待队列中最久的未处理任务，然后将被拒绝的任务添加到等待队列中，并尝试再次提交。 DiscardPolicy ：当任务添加到线程池中被拒绝时，线程池将丢弃被拒绝的任务，如果允许任务丢失，这是最好的方案。关闭线程池线程池使用完毕，需要对其进行关闭，有两种方法 shutdown() 说明：shutdown并不是直接关闭线程池，而是不再接受新的任务…如果线程池内有任务，那么把这些任务执行完毕后，关闭线程池 shutdownNow() 说明：这个方法表示不再接受新的任务，并把任务队列中的任务直接移出掉，如果有正在执行的，尝试进行停止 线程池的底层工作原理 提交任务 核心线程是否已满？ Y 跳转至第3步； N 创建执行线程 队列已满？ Y 跳转至第4步； N 加入队列 最大线程已满？ Y 跳转至第5步； N 创建线程 拒绝策略 如何配置合理的线程数线程池中线程数目的设置依托于硬件设备（CPU核数）以及需要执行任务的类型12//查看CPU核数System.out.println(Runtime.getRuntime().availableProcessors()); CPU密集型任务： 特点：大量运算，没有阻塞，CPU一直全速运行 配置：应配置尽可能少的线程数量。 公式：CPU核数 + 1 IO密集型任务： 特点：大部分线程阻塞，CPU不是一直执行任务 配置：应配置尽可能多的线程数量。如：CPU核数 * 2 公式：CPU核数 / (1 - 阻塞系数) 阻塞系数约为0.8~0.9]]></content>
      <categories>
        <category>ThreadPool</category>
      </categories>
      <tags>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC初探]]></title>
    <url>%2F2019%2F05%2F15%2FJUC%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[一、JUC 简介JUC：java.util.concurrent 在并发编程中使用的工具类 二、Lock 接口1. Synchronized1.1 多线程编程模板 线程 操作 资源类 判断 干活 通知 高内聚低耦合 注意：多线程的判断必须使用while循环，不能使用if1.2 实现步骤 创建资源类 资源类里创建同步方法、同步代码块2. Lock2.1 Lock是什么Lock 实现提供更广泛的锁定操作可以比使用synchronized 获得方法和声明更好。他们允许更灵活的结构，可以有完全不同的特性，可以支持多个相关的Condition 对象。2.2 Lock接口的实现ReentrantLock 可重入锁，参考Java8API2.3 lambda 表达式 要求：lambda 表达式，如果一个接口只有一个方法，我可以把方法名省略 编写规则：拷贝小括号（），写死右箭头-&gt;，落地大括号{…} 1Foo foo = () -&gt; &#123;System.out.println(&quot;****hello lambda&quot;);&#125;; 函数式接口：lambda 表达式，必须是函数式接口，必须只有一个方法，如果接口只有一个方法java 默认它为函数式接口。为了正确使用Lambda 表达式，需要给接口加个注解：@FunctionalInterface，如有两个方法，立刻报错。 2.4 Lock与Synchronized的区别，用Lock有什么好处 原始构成： synchronized是关键字，属于JVM层面monitorenter（底层通过monitor对象来完成，wait/notify等方法也依赖于monitor对象，只有再同步块和方法中才能调用wait/notify等方法）， monitorexit lock是具体类（java.util.concurrent.locks.Lock）是API层面的锁 使用方法： synchronized不需要用户手动释放锁，当synchronized代码执行完后，系统会自动让线程释放对锁的占用 ReentrantLock则需要用户手动释放锁，若没有主动释放，就有可能出现死锁的情况，需要lock()和unlock()方法配合try/finally语句块来完成 等待是否可中断： synchronized不可中断，除非抛出异常或正常运行完成 ReentrantLock可中断，（1）设置超时方法tryLock(long timeout, TimeUnit unit)（2）LockInterruptibly()放在代码块中，调用interrupt()方法可中断 加锁是否公平： synchronized为非公平锁 ReentrantLock两者都可以，默认非公平锁，构造方法可传入boolean值，true为公平锁，false为非公平锁 绑定多个条件的condition： synchronized没有 ReentrantLock可以实现分组唤醒需要被唤醒的线程，可以精确唤醒，而不是像synchronized要么随机唤醒一个线程，要么全部唤醒 三、Callable 接口1. 是什么1.1 面试题：获得多线程的方法几种？错误回答：（1）继承thread 类（2）runnable 接口正确回答：传统的是继承thread 类和实现runnable 接口，java5 以后又有实现callable 接口和java 的线程池获得。 1.2 功能接口Callable 是一个功能接口，因此可以用作lambda 表达式或方法引用的赋值对象。 2. 与 runnable 对比 Callable有返回值 Callable会抛异常 接口实现的方法不同 call()和run() 3. 如何使用3.1 FutureTask FutureTask 未来的任务，用它就干一件事，异步调用。 main 方法就像一个冰糖葫芦，一个个方法由main 串起来。但解决不了一个问题：正常调用挂起堵塞问题 例子：高考：会做的先做，不会的放在后面做 在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把这些作业交给Future 对象在后台完成，当主线程将来需要时，就可以通过Future 对象获得后台作业的计算结果或者执行状态。 一般FutureTask 多用于耗时的计算，主线程可以在完成自己的任务后，再去获取结果。 仅在计算完成时才能检索结果；如果计算尚未完成，则阻塞get 方法。一旦计算完成，就不能再重新开始或取消计算。get 方法而获取结果只有在计算完成时获取，否则会一直阻塞直到任务转入完成状态，然后会返回结果或者抛出异常。 只计算一次，且get 方法一般放到最后，若不放在最后一般使用 while (!futureTask.isDone()) 循环 1234567FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new MyThread());//共用一个FutureTask只会进1次new Thread(futureTask,&quot;AA&quot;).start();new Thread(futureTask,&quot;BB&quot;).start(); int r2 = futureTask.get(); 四、线程间的通信1. 线程间通信（1）生产者+消费者（2）通知等待唤醒机制 2. synchronized 实现1234567891011public synchronized void increment() throws InterruptedException&#123; //1 判断 if(number !=0 ) &#123; this.wait(); &#125; //2 干活 ++number; System.out.println(Thread.currentThread().getName()+&quot;\t&quot;+number); //3 通知 this.notifyAll();&#125; 3. lock实现3.1 对标synchronizedsynchronized———wait———notifylock———await———signal 3.2 conditionsynchronized没有，ReentrantLock可以实现分组唤醒需要被唤醒的线程，可以使用condition进行精确唤醒（有顺序通知，需要有标识位），而不是像synchronized要么随机唤醒一个线程，要么全部唤醒。 12345//1 判断while(number != 3)&#123; //number就是标识位 //A 就要停止 c3.await();&#125;]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java阻塞队列：BlockingQueue]]></title>
    <url>%2F2019%2F05%2F14%2FJava%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%EF%BC%9ABlockingQueue%2F</url>
    <content type="text"><![CDATA[阻塞队列：BlockingQueue阻塞队列是一种队列，一种可以在多线程环境下使用，并且支持阻塞等待的队列。也就是说，阻塞队列和一般的队列的区别就在于： 多线程环境支持，多个线程可以安全的访问队列 支持生产和消费等待，多个线程之间互相配合，当队列为空的时候，消费线程会阻塞等待队列不为空；当队列满了的时候，生产线 程就会阻塞直到队列不满。 几种常用的阻塞队列 ArrayBlockingQueue，基于数组结构的有界阻塞队列，按FIFO对元素进行排序 LinkedBlockingQueue，基于链表结构的阻塞队列，按FIFO对元素进行排序，有界但大小默认值为Integer.MAX_VALUE = 2 的 31 次方 - 1 LinkedBlockingDeque，基于链表结构的双端阻塞队列 LinkedTransferDeque，基于链表结构的无界阻塞队列 DelayQueue，使用优先级队列实现的延时无界阻塞队列 PriorityBlockingQueue，支持优先级排序的无界阻塞队列，在需要多线程支持、需要优先级队列支持的场景下会被运用 SynchronousQueue同步队列，一个不存储元素的阻塞队列，每个插入操作必须等另一个线程调用移出操作，否则插入操作会一致阻塞（单个元素的队列） 使用场景阻塞队列在java中的一种典型使用场景是线程池，在线程池中，当提交的任务不能被立即得到执行的时候，线程池就会将提交的任务放到一个阻塞的任务队列中来，比如下面的代码：12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; newFixedThreadPool使用了LinkedBlockingQueue这种阻塞队列。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; newCachedThreadPool使用了SynchronousQueue这种队列，这种队列的特点是不缓存数据，而是缓存线程，线程分为生产者线程和消费者线程，一个生产者线程和一个消费者线程是互补的，当一个生产者线程遇到一个消费者线程的时候就会直接进行数据交换，所以这种队列的技术点比较高，理解起来难度较大。一个线程只能缓存一个数据，当一个线程插入数据之后就会被阻塞，直到另外一个线程消费了其中的数据。 阻塞队列还提供了其他类型的队列，包括双端阻塞队列，延时阻塞队列，延时阻塞队列的使用可以在newScheduledThreadPool中找到，newScheduledThreadPool里面使用延时阻塞队列来调度周期性任务执行。 BlockingQueue提供的一些方法根据插入和取出两种类型的操作，具体分为下面一些类型：|操作类型| Throws Exception |Special Value|Blocks|Times out||–|–|–|–|–||插入| add(o) |offer(o)|put(o)|offer(o, timeout, unit)||取出(删除) | remove(o) |poll()|take()|poll(timeout, unit)||Examine(检查)| element() |peek()|not applicable|not applicable| Throws Exception 类型的插入和取出在不能立即被执行的时候就会抛出异常。 Special Value 类型的插入和取出在不能被立即执行的情况下会返回一个特殊的值（true 或者 false） Blocked 类型的插入和取出操作在不能被立即执行的时候会阻塞线程直到可以操作的时候会被其他线程唤醒 Timed out 类型的插入和取出操作在不能立即执行的时候会被阻塞一定的时间，如果在指定的时间内没有被执行，那么会返回一个特殊值 ArrayBlockingQueueArrayBlockingQueue需要你提供数组的大小，下面是ArrayBlockingQueue提供的三个构造函数：12345public ArrayBlockingQueue(int capacity): // 初始化数组大小public ArrayBlockingQueue(int capacity, boolean fair): //初始化数组大小，并且设定是否是fair模式 public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) //初始化数组大小，设置是否是fair模式，然后使用一个集合初始化阻塞队列 在构造函数中有两个比较关键的参数，一个是capacity代表阻塞队列使用的数组的长度，另外一个是fair，代表阻塞队列的一种策略选择，用于构造用于线程同步的锁（ReentrantLock）是公平锁还是非公平锁，默认值为false，非公平锁 SynchronousQueueSynchronousQueue不存在容量的说法，任何插入操作都需要等待其他线程来消费，否则就会阻塞等待，也就是说，生产线程生产出一条数据之后就要等待消费者线程来将其消费掉，才能继续生产数据，否则就会阻塞等待消费。 SynchronousQueue通过使用Transferer类的transfer(E e, boolean timed, long nanos)方法来完成数据交易操作，根据fair模式和non-fair模式有两种类型的Transferer，fair模式对应于TransferQueue，non-fair模式对应TransferStack。 总结：为什么使用BlockingQueue使用阻塞队列，程序员不再需要关心什么时候该阻塞/唤醒线程]]></content>
      <categories>
        <category>阻塞队列</category>
      </categories>
      <tags>
        <tag>JUC</tag>
        <tag>阻塞队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用ideal创建java项目，并添加maven管理]]></title>
    <url>%2F2019%2F05%2F13%2F%E7%94%A8ideal%E5%88%9B%E5%BB%BAjava%E9%A1%B9%E7%9B%AE%EF%BC%8C%E5%B9%B6%E6%B7%BB%E5%8A%A0maven%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[第一步 创建项目File—&gt;New—&gt;Project 第二步 修改项目结构在项目的src下面创建main/java和main/resources目录. File—&gt;Project Structure 或者快捷键Ctrl+Shift+Alt+s.将Sources定位到java目录下，将Resources定位到resources下面. 此处补充idea下的java项目关于不同资源的标识符。 Sources 一般用于标注类似 src 这种可编译目录。有时候我们不单单项目的 src 目录要可编译，还有其他一些特别的目录也许我们也要作为可编译的目录，就需要对该目录进行此标注。只有 Sources 这种可编译目录才可以新建 Java 类和包，这一点需要牢记。 Tests 一般用于标注可编译的单元测试目录。在规范的 maven 项目结构中，顶级目录是src，maven 的 src 我们是不会设置为Sources 的，而是在其子目录 main 目录下的 java 目录，我们会设置为 Sources。而单元测试的目录是 src - test - java，这里的 java 目录我们就会设置为 Tests，表示该目录是作为可编译的单元测试目录。一般这个和后面几个我们都是在 maven 项目下进行配置的，但是我这里还是会先说说。从这一点我们也可以看出 IntelliJ IDEA 对 maven 项目的支持是比彻底的。 Resources 一般用于标注资源文件目录。在 maven 项目下，资源目录是单独划分出来的，其目录为：src - main -resources，这里的 resources 目录我们就会设置为 Resources，表示该目录是作为资源目录。资源目录下的文件是会被编译到输出目录下的。 Test Resources 一般用于标注单元测试的资源文件目录。在 maven 项目下，单元测试的资源目录是单独划分出来的，其目录为：src - test -resources，这里的 resources 目录我们就会设置为 Test Resources，表示该目录是作为单元测试的资源目录。资源目录下的文件是会被编译到输出目录下的。 Excluded 一般用于标注排除目录。被排除的目录不会被 IntelliJ IDEA 创建索引，相当于被 IntelliJ IDEA 废弃，该目录下的代码文件是不具备代码检查和智能提示等常规代码功能。 通过上面的介绍，我们知道对于非 maven 项目我们只要会设置 src 即可。第三步 添加maven管理选中项目——&gt;右键——&gt;选择Add Framworks Support——&gt;选择maven 此时就会生成pom.xml文件，可以在该文件里面添加项目的依赖了]]></content>
      <categories>
        <category>Ideal</category>
      </categories>
      <tags>
        <tag>Ideal</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC的几个常用辅助类]]></title>
    <url>%2F2019%2F05%2F13%2FJUC%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B8%B8%E7%94%A8%E8%BE%85%E5%8A%A9%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[1. ReentrantReadWriteLock 读写锁 多个线程同时读一个资源类没有问题，所以为了满足并发量，读取共享资源应该可以同时进行。 但是写共享资源只能有一个线程。 写操作：原子+独占，整个过程必须是一个完整的统一体，中间不许被分割，被打断。 总结： 读-读可以共存 读-写不可以共存 写-写不可以共存 1234567写锁reentrantReadWriteLock.writeLock().lock();reentrantReadWriteLock.writeLock().unlock();读锁reentrantReadWriteLock.readLock().lock();reentrantReadWriteLock.readLock().unlock(); 2. CountDownLatch 减少计数 CountDownLatch 主要有两个方法，当一个或多个线程调用await 方法时，这些线程会阻塞。 其它线程调用countDown 方法会将计数器减1(调用countDown 方法的线程不会阻塞)，当计数器的值变为0 时，因await 方法阻塞的线程会被唤醒，继续执行。123456//自定义计数值java.util.concurrent.CountDownLatch countDownLatch = new java.util.concurrent.CountDownLatch(6);//计数值减1countDownLatch.countDown();//线程阻塞countDownLatch.await(); 3. CyclicBarrier 循环栅栏 CyclicBarrier 的字面意思是可循环（Cyclic）使用的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞,直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。 线程进入屏障通过CyclicBarrier 的await()方法。123CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()-&gt;&#123;System.out.println(&quot;召唤神龙&quot;);&#125;);cyclicBarrier.await(); 4. Semaphore 信号灯在信号量上我们定义两种操作： acquire（获取） 当一个线程调用acquire 操作时，它要么通过成功获取信号量（信号量减1），要么一直等下去，直到有线程释放信号量，或超时。 release（释放）实际上会将信号量的值加1，然后唤醒等待的线程。 信号量主要用于两个目的，一个是用于多个共享资源的互斥使用，另一个用于并发线程数的控制。 12345Semaphore semaphore = new Semaphore(3); //模拟3个车位semaphore.acquire();//获取semaphore.release();//释放]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java插件Lombok的介绍和使用方法]]></title>
    <url>%2F2019%2F05%2F13%2FJava%E6%8F%92%E4%BB%B6Lombok%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. Lombok背景介绍官方介绍如下： Project Lombok makes java a spicier language by adding ‘handlers’ that know how to build and compile simple, boilerplate-free, not-quite-java code.大致意思是Lombok通过增加一些“处理程序”，可以让java变得简洁、快速。 2. Lombok使用方法Lombok能以简单的注解形式来简化java代码，提高开发人员的开发效率。例如开发中经常需要写的javabean，都需要花时间去添加相应的getter/setter，也许还要去写构造器、equals等方法，而且需要维护，当属性多时会出现大量的getter/setter方法，这些显得很冗长也没有太多技术含量，一旦修改属性，就容易出现忘记修改对应方法的失误。 Lombok能通过注解的方式，在编译时自动为属性生成构造器、getter/setter、equals、hashcode、toString方法。出现的神奇就是在源码中没有getter和setter方法，但是在编译生成的字节码文件中有getter和setter方法。这样就省去了手动重建这些代码的麻烦，使代码看起来更简洁些。 Lombok的使用跟引用jar包一样，可以在官网（https://projectlombok.org/download）下载jar包，也可以使用maven添加依赖：123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 2.1 @Data@Data注解在类上，会为类的所有属性自动生成setter/getter、equals、canEqual、hashCode、toString方法，如为final属性，则不会为该属性生成setter方法。 2.2 @Getter/@Setter如果觉得@Data太过残暴（因为@Data集合了@ToString、@EqualsAndHashCode、@Getter/@Setter、@RequiredArgsConstructor的所有特性）不够精细，可以使用@Getter/@Setter注解，此注解在属性上，可以为相应的属性自动生成Getter/Setter方法。 2.3 @NonNull该注解用在属性或构造器上，Lombok会生成一个非空的声明，可用于校验参数，能帮助避免空指针。 示例如下：12345678910import lombok.NonNull;public class NonNullExample extends Something &#123; private String name; public NonNullExample(@NonNull Person person) &#123; super(&quot;Hello&quot;); this.name = person.getName(); &#125;&#125; 不使用Lombok：12345678910111213import lombok.NonNull;public class NonNullExample extends Something &#123; private String name; public NonNullExample(@NonNull Person person) &#123; super(&quot;Hello&quot;); if (person == null) &#123; throw new NullPointerException(&quot;person&quot;); &#125; this.name = person.getName(); &#125;&#125; 2.4 @Cleanup该注解能帮助我们自动调用close()方法，很大的简化了代码。 示例如下：123456789101112131415import lombok.Cleanup;import java.io.*;public class CleanupExample &#123; public static void main(String[] args) throws IOException &#123; @Cleanup InputStream in = new FileInputStream(args[0]); @Cleanup OutputStream out = new FileOutputStream(args[1]); byte[] b = new byte[10000]; while (true) &#123; int r = in.read(b); if (r == -1) break; out.write(b, 0, r); &#125; &#125;&#125; 不使用Lombok：1234567891011121314151617181920212223242526import java.io.*;public class CleanupExample &#123; public static void main(String[] args) throws IOException &#123; InputStream in = new FileInputStream(args[0]); try &#123; OutputStream out = new FileOutputStream(args[1]); try &#123; byte[] b = new byte[10000]; while (true) &#123; int r = in.read(b); if (r == -1) break; out.write(b, 0, r); &#125; &#125; finally &#123; if (out != null) &#123; out.close(); &#125; &#125; &#125; finally &#123; if (in != null) &#123; in.close(); &#125; &#125; &#125;&#125; 2.5 @EqualsAndHashCode默认情况下，会使用所有非静态（non-static）和非瞬态（non-transient）属性来生成equals和hasCode，也能通过exclude注解来排除一些属性。 示例如下：12345678910111213141516171819202122232425import lombok.EqualsAndHashCode;@EqualsAndHashCode(exclude=&#123;&quot;id&quot;, &quot;shape&quot;&#125;)public class EqualsAndHashCodeExample &#123; private transient int transientVar = 10; private String name; private double score; private Shape shape = new Square(5, 10); private String[] tags; private int id; public String getName() &#123; return this.name; &#125; @EqualsAndHashCode(callSuper=true) public static class Square extends Shape &#123; private final int width, height; public Square(int width, int height) &#123; this.width = width; this.height = height; &#125; &#125;&#125; 2.6 @ToString类使用@ToString注解，Lombok会生成一个toString()方法，默认情况下，会输出类名、所有属性（会按照属性定义顺序），用逗号来分割。 通过将includeFieldNames参数设为true，就能明确的输出toString()属性。这一点是不是有点绕口，通过代码来看会更清晰些。 示例如下：123456789101112131415161718192021222324import lombok.ToString;@ToString(exclude=&quot;id&quot;)public class ToStringExample &#123; private static final int STATIC_VAR = 10; private String name; private Shape shape = new Square(5, 10); private String[] tags; private int id; public String getName() &#123; return this.getName(); &#125; @ToString(callSuper=true, includeFieldNames=true) public static class Square extends Shape &#123; private final int width, height; public Square(int width, int height) &#123; this.width = width; this.height = height; &#125; &#125;&#125; 不使用Lombok：123456789101112131415161718192021222324252627282930import java.util.Arrays;public class ToStringExample &#123; private static final int STATIC_VAR = 10; private String name; private Shape shape = new Square(5, 10); private String[] tags; private int id; public String getName() &#123; return this.getName(); &#125; public static class Square extends Shape &#123; private final int width, height; public Square(int width, int height) &#123; this.width = width; this.height = height; &#125; @Override public String toString() &#123; return &quot;Square(super=&quot; + super.toString() + &quot;, width=&quot; + this.width + &quot;, height=&quot; + this.height + &quot;)&quot;; &#125; &#125; @Override public String toString() &#123; return &quot;ToStringExample(&quot; + this.getName() + &quot;, &quot; + this.shape + &quot;, &quot; + Arrays.deepToString(this.tags) + &quot;)&quot;; &#125;&#125; 2.7 @NoArgsConstructor, @RequiredArgsConstructor and @AllArgsConstructor无参构造器、部分参数构造器、全参构造器。Lombok没法实现多种参数构造器的重载。 示例如下：12345678910111213141516import lombok.AccessLevel;import lombok.RequiredArgsConstructor;import lombok.AllArgsConstructor;import lombok.NonNull;@RequiredArgsConstructor(staticName = &quot;of&quot;)@AllArgsConstructor(access = AccessLevel.PROTECTED)public class ConstructorExample&lt;T&gt; &#123; private int x, y; @NonNull private T description; @NoArgsConstructor public static class NoArgsExample &#123; @NonNull private String field; &#125;&#125; 不使用Lombok：12345678910111213141516171819202122232425262728 public class ConstructorExample&lt;T&gt; &#123; private int x, y; @NonNull private T description; private ConstructorExample(T description) &#123; if (description == null) throw new NullPointerException(&quot;description&quot;); this.description = description; &#125; public static &lt;T&gt; ConstructorExample&lt;T&gt; of(T description) &#123; return new ConstructorExample&lt;T&gt;(description); &#125; @java.beans.ConstructorProperties(&#123;&quot;x&quot;, &quot;y&quot;, &quot;description&quot;&#125;) protected ConstructorExample(int x, int y, T description) &#123; if (description == null) throw new NullPointerException(&quot;description&quot;); this.x = x; this.y = y; this.description = description; &#125; public static class NoArgsExample &#123; @NonNull private String field; public NoArgsExample() &#123; &#125; &#125;&#125; 4. Idea下安装Lombok插件可直接通过搜索获取另外还有一个关键点：接下来就可以编码了 5. Lombok的优缺点优点： 能通过注解的形式自动生成构造器、getter/setter、equals、hashcode、toString等方法，提高了一定的开发效率 让代码变得简洁，不用过多的去关注相应的方法 属性做修改时，也简化了维护为这些属性所生成的getter/setter方法等 缺点： 不支持多种参数构造器的重载 虽然省去了手动创建getter/setter方法的麻烦，但大大降低了源代码的可读性和完整性，降低了阅读源代码的舒适度 6. 总结Lombok虽然有很多优点，但Lombok更类似于一种IDE插件，项目也需要依赖相应的jar包。 Lombok依赖jar包是因为编译时要用它的注解，为什么说它又类似插件？因为在使用时，eclipse或IntelliJ IDEA都需要安装相应的插件，在编译器编译时通过操作AST（抽象语法树）改变字节码生成，变向的就是说它在改变java语法。它不像spring的依赖注入或者mybatis的ORM一样是运行时的特性，而是编译时的特性。这里我个人最感觉不爽的地方就是对插件的依赖！因为Lombok只是省去了一些人工生成代码的麻烦，但IDE都有快捷键来协助生成getter/setter等方法，也非常方便。]]></content>
      <categories>
        <category>Lombok</category>
      </categories>
      <tags>
        <tag>Ideal</tag>
        <tag>Lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ideal如何自定义模板]]></title>
    <url>%2F2019%2F05%2F13%2Fideal%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[关于模板(Template) ( Editor - Live Templates 和 Editor - General - Postfix Completion ) 1. Live Templates(实时代码模板)功能介绍它的原理就是配置一些常用代码字母缩写，在输入简时可以出现你预定义的固定模式的代码，使得开发效率大提高 ，同时也可以增加个性化 。最简单的例子 就是在Java中输入sout会出现System.out.println(); 2. 已有的常用模板Postfix Completion 默认如下：Live Templates 默认如下：二者的区别：Live Templates 可以自定义，而 Postfix Completion 不行。有些操作二者都提供了模板，但Postfix Completion 较之 Live Templates 快0.01S。 举例： fori：可生成for循环 iter：可生成增强型for循环 itar：可生成普通for循环 list.for：可生成集合list的for循环，又如：list.fori 或 list.forr ifn：可生成if(xxx = null) prsf：可生成private static final 3. 自定义模板先定义一个模板的分组：选中自定义的模板组，点击“+”来定义模板自定义步骤如下： Abbreviation：模板的缩写 Description：模板的描述 Template text：模板的代码片段 Define：应用范围]]></content>
      <categories>
        <category>Ideal</category>
      </categories>
      <tags>
        <tag>Ideal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis初探]]></title>
    <url>%2F2019%2F05%2F10%2FRedis%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[Sql对比NoSqlSql： 访问和处理关系数据库的计算机标准语言。mysql数据库，数据库以“文件形式存储在硬盘”里边。 NoSql： CAP： 强一致性（C），可用性（A），分区容错性（P） CAP核心理论：最多只能很好的满足两个特性 CAP的3进2：分区容错性必须要实现，只能在一致性和可用性之间权衡 redis：CP 网站架构的大多选择：AP Redis1. 什么是RedisRedis是远程数据服务，内存高速缓存数据库，支持丰富的数据结构，如String、list、hash、set、sorted set，可持久化，保证了数据安全。Redis是做数据缓存的。 缓存有两种类型：数据缓存、页面缓存 使用缓存减轻数据库的负载。 在开发的时候如果有一些数据在短时间之内不会发生变化，而他们还要被频繁的访问，为了提高用户的请求速度和降低网站的负载，就把这些数据放到一个读取速度更快的介质上（或者是通过较少的计算量就可以获得该数据），该行为就称作对该数据的缓存。 该介质可以是文件、数据库、内存，内存经常用于数据缓存。 缓存的两种形式： 页面缓存经常用在CMS内存管理系统里边 数据缓存经常用于页面的具体数据里边 新闻页面（内容单一，集中）适合做页面缓存商品页面的组成部分根据业务特点，各个部分数据比较独立，适合给他们分别做数据缓存。 2. redis和memcache比较 Redis和Memcache都是将数据存放在内存中，都是内存数据库。不过memcache还可用于缓存其他东西，例如图片、视频等等。 Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持master-slave（主从）模型应用 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用 Redis单个value的最大限制是1GB，memcached只能保存1MB的数据。 在Redis中，并不是所有的数据都一直存储在内存中的。这是和Memcached相比一个最大的区别（我个人是这么认为的）。 3. redis常见使用场景 会话缓存（最常用） 消息队列（如支付） 活动排行榜或计数 发布、订阅消息（消息通知） 商品列表，评论列表 具体使用1. key的操作在redis里边，除了“\n”和空格不能作为名字的组成部分，其他内容都可以作为key的名字部分。名字长度不作要求。 2. String类型操作 String是redis最基本的类型 Redis的string可以包含任何数据。包括jpg图片或者序列化对象 单个value值最大上限是1G字节 如果只用string类型，redis就可以被看做加上持久化特性的memcache incr：increament增长 该指令可以对key进行累加1操作，默认是累加1操作，类似i++操作 该指令可以针对**新key**或**已有key**进行操作 新key：创建该key并累加1，其值为1 已有key：key的信息值类型要求必须为整型的 decr的操作模式与incr一致，不过其是减1操作 substr：对内容进行截取，包括start和end标记位置 3. 数据类型List链表list类型其实就是一个双向链表。通过push，pop操作从链表的头部或者尾部添加删除元素。这使得list既可以用作栈，也可以用作队列。 List类型操作： lpush key string：在key对应list的头部添加字符串元素 rpop key：从list的尾部删除元素，并返回删除元素 llen key 返回 key：对应list的长度，key不存在返回0，如果key对应key不是list返回错误 lrange key start end：返回指定区间内的元素，下标从0开始 rpush key string：同上，在尾部添加 lpop key：从list的头部删除元素，并返回删除元素 ltrim key start end：截取list，保留指定区间内元素 list链表类型应用场合： 获得最新的10个登录用户信息：select * from user order by logintime desc limit 10； 以上sql语句可以实现用户需求，但是数据多的时候，全部数据都要受到影响，对数据库的复杂比较高。必要情况还需要给关键字段（id或logintime）设置索引，索引也比较耗费系统资源。 如果通过list链表实现以上功能，可以在list链表中只保留最新的10个数据，每进来一个新数据就删除一个旧数据。每次就可以从链表中直接获得需要的数据。极大节省各方面资源消耗。 4. set集合类型 redis的set是string类型的无序集合。 set元素最大可以包含（2的32次方-1）个元素 关于set集合类型除了基本的添加删除操作，其他有用的操作还包括集合的取并集，交集，差集。通过这些操作可以很容易的实现sns的好友推荐功能。 注意：每个集合中的各个元素不能重复 set类型操作：123456789·sadd key member：添加一个string元素到key对应的set集合中，成功返回1，如果元素已经在 set集合中，返回0，key对应的set不存在返回错误。·sren key member [member]:从key对应set中移除给定元素，成功返回1·smove p1 p2 member：从p1对应set中移除member并添加到p2对应set中·scard key：返回set元素个数·sismember key member：判断set的元素个数·sinter key1 key2...keyN：返回所有给定key的交集·sunion key1 key2...keyN：返回所有给定并集·sdiff key1 key2...keyN:返回所有给定key的差集·smembers key：返回key对应set的所有元素，结果是无序的。 set类型应用场合：qq好友推荐 Tom朋友圈（与某某是好友）：mary jack xiaoming wang5 wang6Linken朋友圈（与某某是好友）：yuehan daxiang luce wang5 wang6创建Tom的朋友圈：创建linken朋友圈：对两个set取交集和并集：取差集： 5. Sort Set排序集合类型 和set一样sorted set也是string类型元素的集合，不同的是每个元素都会关联一个权。通过权值可以有序的获取集合中的元素。 排序集合中的每个元素都是值、权的组合，之前的set集合类型每个元素就只有一个值。 sort set排序类型：12345678910·zadd key score member：添加元素到集合，元素在集合中存在则更新对应score。·zren key member：删除指定元素，1表示成功，如果元素不存在返回0·zincrby key incr member：按照incr幅度增加对应member的score值，返回score值·zrank key member：返回指定元素在集合中的排名（下标），集合中元素是按score从小到大排序 的。·zrevrank key member：同上，但是集合中元素是按score从大到小排序的·zrange key start end：类似lrange操作从集合中去指定区间的元素。返回的是有序结果·zrevrange key start end：同上，返回结果是按score逆序的。·zcard key：返回集合中元素个数。·zscore key element：返回给定元素对应的score·zrenrangeburank key min max：删除集合中排名在给定区间的元素。 Sort set类型适合场合： 获得热门帖子（回复量）信息：select * from message order by backnum desc limit 5；（以上需求可以通过简单的sql语句实现，但是sql语句比较耗费mysql数据库资源） 案例：获得热门帖子信息（前5）：我们只做一个sort set排序集合，里边只保留5个元素信息，该5个元素是回复量最高的每个帖子被回复的时候，都有机会进入该集合里边，但是只有回复量最高的前5个帖子会存在于该集合，回复量低的就被删除。 6. 数据类型Hash 是一个键值对集合，是string类型的field和value的映射表，适合存储对象 hash数据类型存储的数据与mysql数据库中存储的一条记录极为相似。 持久化功能Redis为了内部数据的安全考虑，会把本身的数据以文件形式保存到硬盘中一份，在服务器重启之后会把硬盘的数据恢复到内存（redis）的里边。 数据保存到硬盘的过程就称为“持久化”效果。 1. snap shotting快照持久化（RDB持久化）（保存结果） 该持久化默认开启，一次性把redis中全部的数据保存一份存储到硬盘中，适合大规模数据恢复，但数据一致性和完整性差 手动发起快照持久化指令：bgsave指令 默认的文件名为：dump.rdb 快照持久化的备份频率：save 900 1 #900秒内如果超过1个key被修改，则发起快照保存save 300 10 #300秒超过10个key被修改，发起快照保存save 60 10000 #60秒超过10000个key被修改，发起快照保存 2. append only file（AOF持久化）（保存操作） 本质：把用户执行的每个“写”指令（添加、删除、修改）都备份到文件中，还原数据的时候就是执行具体写指令而已。 开启AOF持久化（会清空redis内部的数据） 默认没有开启 手动开启，完整性高，但内容较多的情况下会影响恢复效率 3. 应用场合 若只是使用redis作为缓存，可关闭持久化 若使用持久化功能，rdb与aof都建议开启 4. RDB持久化和AOF持久化的对比RDB： 优点：节省磁盘空间，恢复速度快 缺点：数据庞大时仍然消耗性能，如果redis down掉会丢失最后一次快照的所有更改 AOF: 优点：丢失数据概率更低，日志文件可读性高，可处理错误的操作 缺点 ：相比RDB更占空间，恢复/备份更慢，读写同步会有性能压力 主从模式 master—slave 为了降低每个redis服务器的负载，可以多设置几个，并做主从模式，一个服务器负责“写”数据，其他服务器负责“读”数据，主服务器数据会“自动”同步给从服务器。 Slave服务器默认禁止写操作。 主从复制 主从复制 作用：读写分离，容灾恢复 配从不配主。常用三招：一主二仆、薪火相传、反客为主 哨兵机制 主从切换，多哨兵模式]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>NoSql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ideal项目如何与github同步(pull,push)]]></title>
    <url>%2F2019%2F05%2F09%2FIdeal%E9%A1%B9%E7%9B%AE%E5%A6%82%E4%BD%95%E4%B8%8Egithub%E5%90%8C%E6%AD%A5-pull-push%2F</url>
    <content type="text"><![CDATA[从GitHub更新项目到Ideal（pull） 右击项目名 –&gt; Git –&gt; Repository –&gt; pull 从Ideal更新项目到GitHub（push） 右击项目名 –&gt; Git –&gt; commit diretory 右击项目名 –&gt; Git –&gt; Repository –&gt; push]]></content>
      <categories>
        <category>Ideal</category>
      </categories>
      <tags>
        <tag>Ideal</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA新建Maven web项目]]></title>
    <url>%2F2019%2F05%2F09%2FIntelliJ-IDEA%E6%96%B0%E5%BB%BAMaven-web%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[第一次使用Intellij idea，有诸多不熟悉，之处，网上很多教程千差万别，为日后少走弯路，特此记录。 步骤一：首先先创建一个project，打开-File-New-Project 步骤二：你要选择maven然后按照下面图片 的指示操作就可以了点击next按钮点击next，该图为示例图片，XX为你自己设置的项目名，如im，之后点击finish，等idea完全加载完成后，就可以看到项目已经生成了（有时也缺少下图中的resources目录，也需要手动创建）步骤三：配置tocat服务器。点击那个倒立的三角形，然后点击Edit Configurations配置artifacts，标签由Server跳到Deploment，点击小铅笔一样的图标对artifacts进行配置]]></content>
      <categories>
        <category>Ideal</category>
      </categories>
      <tags>
        <tag>Ideal</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用Ideal上传本地项目至GitHub]]></title>
    <url>%2F2019%2F05%2F08%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Ideal%E4%B8%8A%E4%BC%A0%E6%9C%AC%E5%9C%B0%E9%A1%B9%E7%9B%AE%E8%87%B3GitHub%2F</url>
    <content type="text"><![CDATA[IDEA配置github并上传项目配置GitHub 在github中创建一个账号：https://github.com/join?source=header-home 下载并安装git：https://git-scm.com/downloads 安装成功后打开Git Bash，输入下列命令，设置git全局用户名和邮箱 12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 在IDEA中设置Git，在File–&gt;Setting-&gt;Version Control–&gt;Git–&gt;Path to Git executable选择你的git安装后的git.exe文件，然后点击Test，测试是否设置成功要是在bin目录下没找到此exe，不妨看看cmd目录下面有没有，也就是c://~install/cmd/git.exe; 在IDEA中设置GitHub，File–&gt;Setting-&gt;Version Control–&gt;GibHub Host：github.com Token：点击Create API Token，输入在github中注册的用户名和密码生成token 点击Test，测试是否连接成功 创建本地仓库，VCS–&gt;Import into Version Control–&gt;Create Git Repository…(要给自己的项目建立一个git本地仓库,因为后面修改代码应当先上传到本地仓库，再从本地仓库上传到github上)在弹框中选中项目所在的位置，点击OK，此时项目文件全部变成红色（若选中其他位置，则git–&gt;add不可点选，不知为何） 上传项目到本地仓库，项目右键选择Git–&gt;add，此时项目文件变成绿色，此时文件只是处于暂存区，并没有真正进入到版本库（本地）中。(本步骤是接着第6步骤的，把代码add到暂存区当中) 项目右键Git–&gt; Commit Directory，在弹窗中输入Commit Message，点击commit，此时项目文件从暂存区真正进入版本库中，项目文件变成白色。(此步骤接着第7步骤，只有commint directory才是提交到本地仓库) 上传项目到GitHub中，VCS–&gt;Import into Version Control–&gt;Share Project on GitHub，在弹框中输入仓库名和描述，点击Share，即可是上传，中间会弹窗输入GitHub的用户名和密码（已输入过用户名和密码并记住的不会再次弹框输入），上传成功后IDEA右下角会给出提示 提交修改文件到GitHub新增文件（红色），右键–&gt;Git–&gt;add，将新增的文件加入本地仓库，此时文件变绿色修改文件（蓝色）在项目右键–&gt;Git–&gt;Commit Directory，查看有变动的文件并输入Commit Message，点击Commit and Push…提交后会进行语法检查，若存在错误或警告会给出确认提示，点击Commit，弹出Push框，点击Push，上传GitHub成功（因为此时是你自己的项目，所以有权限提交，一般git到别人的项目，应当叫别人给与权限你才能提交）]]></content>
      <categories>
        <category>Ideal</category>
      </categories>
      <tags>
        <tag>Ideal</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库sql实战(2)]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%95%B0%E6%8D%AE%E5%BA%93sql%E5%AE%9E%E6%88%98-2%2F</url>
    <content type="text"><![CDATA[获取所有员工当前的manager，如果当前的manager是自己的话结果不显示，当前表示to_date=’9999-01-01’。结果第一列给出当前员工的emp_no,第二列给出其manager对应的manager_no。123456789101112CREATE TABLE `dept_emp` ( `emp_no` int(11) NOT NULL, `dept_no` char(4) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `dept_manager` ( `dept_no` char(4) NOT NULL, `emp_no` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`)); 123select e.emp_no, m.emp_no manager_no from dept_emp e inner join dept_manager m on e.dept_no = m.dept_no where e.to_date='9999-01-01' and m.to_date='9999-01-01' and e.emp_no&lt;&gt;m.emp_no 用 INNER JOIN 连接两张表，因为要输出自己的经理，得知自己与经理的部门要相同，故有限制条件 de.dept_no = dm.dept_no 再用 WHERE 限制当前员工与当前经理的条件，即 dm.to_date 等于 ‘9999-01-01’ 、de.to_date 等于 ‘9999-01-01’ 、 de.emp_no 不等于 dm.emp_no (e.emp_no&lt;&gt;m.emp_no) 为了增强代码可读性，将 dept_emp 用别名 de 代替，dept_manager 用 dm 代替，最后根据题意将 de.emp_no 用别名 manager_no 代替后输出 获取所有部门中当前员工薪水最高的相关信息，给出dept_no, emp_no以及其对应的salary123456789101112CREATE TABLE `dept_emp` ( `emp_no` int(11) NOT NULL, `dept_no` char(4) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`)); 1234select e.dept_no, e.emp_no, max(s.salary) salary from dept_emp e inner join salaries s on e.emp_no = s.emp_no where e.to_date = '9999-01-01' and s.to_date = '9999-01-01'group by e.dept_no 先用INNER JOIN连接两张表，限制条件是两张表的emp_no相同，即d.emp_no = s.emp_no； 选取每个员工当前的工资水平，用d.to_date = ‘9999-01-01’ AND s.to_date = ‘9999-01-01’作条件限制，因为此表中每条最新记录的 to_date 都用 9999-01-01 表示； 用GROUP BY d.dept_no将每个部门分为一组，用MAX()函数选取每组中工资最高者； 从titles表获取按照title进行分组，每组个数大于等于2，给出title以及对应的数目t。12345CREATE TABLE IF NOT EXISTS &quot;titles&quot; ( `emp_no` int(11) NOT NULL, `title` varchar(50) NOT NULL, `from_date` date NOT NULL, `to_date` date DEFAULT NULL); 12select title, count(emp_no) t from titles group by title having t&gt;=2 用COUNT()函数和GROUP BY语句可以统计同一title值的记录条数 由于WHERE后不可跟COUNT()函数，故用HAVING语句来限定t&gt;=2的条件 where和having的不同之处在于，where是查找之前的限定，而having是查找之后。 从titles表获取按照title进行分组，每组个数大于等于2，给出title以及对应的数目t。注意对于重复的emp_no进行忽略。12select title, count(distinct emp_no) t from titles group by title having t&gt;=2 和上一题类似，注意使用distinct 对重复的emp_no进行忽略 查找employees表所有emp_no为奇数，且last_name不为Mary的员工信息，并按照hire_date逆序排列 12345678CREATE TABLE `employees` ( `emp_no` int(11) NOT NULL, `birth_date` date NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` char(1) NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`)); 123select * from employees where (emp_no%2)=1 and last_name != 'Mary' order by hire_date desc 员工号为奇数，则emp_no取余应为1 last_name不为Mary，用‘！=’ 或 ‘&lt;&gt;’表示 根据hire_date逆序排列，用desc 统计出当前各个title类型对应的员工当前薪水对应的平均工资。结果给出title以及平均工资avg。1234567891011CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`));CREATE TABLE IF NOT EXISTS &quot;titles&quot; ( `emp_no` int(11) NOT NULL, `title` varchar(50) NOT NULL, `from_date` date NOT NULL, `to_date` date DEFAULT NULL); 123select title,avg(salary) as avg from salaries,titles where salaries.emp_no = titles.emp_no and salaries.to_date='9999-01-01' and titles.to_date='9999-01-01'group by title 多表查询，连接查询是一种特殊的多表查询 获取当前（to_date=’9999-01-01’）薪水第二多的员工的emp_no以及其对应的薪水salary123456CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`)); 1234567select emp_no, salary from salaries where to_date='9999-01-01' and salary = (select distinct salary from salaries order by salary desc limit 1,1)或select emp_no,salary from salarieswhere to_date = '9999-01-01'order by salary desc limit 1,1 注意多个人工资相同的情况 查找当前薪水(to_date=’9999-01-01’)排名第二多的员工编号emp_no、薪水salary、last_name以及first_name，不准使用order by123select e.emp_no, max(s.salary), e.last_name, e.first_name from employees e inner join salaries s on e.emp_no=s.emp_no where s.to_date='9999-01-01' and s.salary != (select max(salary) from salaries where to_date='9999-01-01') 本题做法很多，主要思想为多层SELECT嵌套与MAX()函数结合 先利用MAX()函数找出salaries中当前薪水最高者，即SELECT MAX(salary) FROM salaries WHERE to_date = ‘9999-01-01’ 再利用INNER JOIN连接employees与salaries表，限定条件为【同一员工】e.emp_no = s.emp_no、【当前】s.to_date = ‘9999-01-01’与【非薪水最高】s.salary NOT IN (SELECT MAX(salary) FROM salaries WHERE to_date = ‘9999-01-01’) 在以上限制条件下找薪水最高者，即为所有员工薪水的次高者 查找所有员工的last_name和first_name以及对应的dept_name，也包括暂时没有分配部门的员工123456789101112131415161718CREATE TABLE `departments` ( `dept_no` char(4) NOT NULL, `dept_name` varchar(40) NOT NULL, PRIMARY KEY (`dept_no`));CREATE TABLE `dept_emp` ( `emp_no` int(11) NOT NULL, `dept_no` char(4) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `employees` ( `emp_no` int(11) NOT NULL, `birth_date` date NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` char(1) NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`)); 123select e.last_name, e.first_name, dp.dept_name from employees e left outer join dept_emp de on e.emp_no = de.emp_no left outer join departments dp on de.dept_no=dp.dept_no 本题思路为运用两次LEFT JOIN连接嵌套 第一次LEFT JOIN连接employees表与dept_emp表，得到所有员工的last_name和first_name以及对应的dept_no，也包括暂时没有分配部门的员工 第二次LEFT JOIN连接上表与departments表，即连接dept_no与dept_name，得到所有员工的last_name和first_name以及对应的dept_name，也包括暂时没有分配部门的员工 注意： 第一次 left join 是把未分配部门的员工算进去了，但是只得到了部门号，没有部门名，所以第二次也要 left join 把含有部门名 departments 连接起来，否则在第二次连接时就选不上未分配部门的员工了。 查找员工编号emp_no为10001其自入职以来的薪水salary涨幅值growth123456CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`)); 1234SELECT ( (SELECT salary FROM salaries WHERE emp_no = 10001 ORDER BY to_date DESC LIMIT 1) -(SELECT salary FROM salaries WHERE emp_no = 10001 ORDER BY to_date ASC LIMIT 1)) AS growth 先分别找到emp_no=10001的员工的第一次工资记录与最后一次工资记录 再将最后一次工资记录减去第一次工资记录得到入职以来salary的涨幅，最后用别名growth代替]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL查询语句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库sql实战(1)]]></title>
    <url>%2F2019%2F05%2F06%2F%E6%95%B0%E6%8D%AE%E5%BA%93sql%E5%AE%9E%E6%88%98-1%2F</url>
    <content type="text"><![CDATA[查找最晚入职的员工的所有信息数据表定义如下：12345678CREATE TABLE `employees` ( `emp_no` int(11) NOT NULL, `birth_date` date NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` char(1) NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`)); 1select * from employees where hire_date = (select max(hire_date) from employees) 最晚入职的当天未必就一个人，也许有多人，使用排序并限制得只能取得指定数量的结果。因此不使用limit和top，而是使用聚合查询的max函数求出最晚的入职时间，按最晚入职时间进行查询。 查找入职员工时间排名倒数第三的员工所有信息 1select * from employees where hire_date = (select distinct hire_date from employees order by hire_date desc limit 2,1) distinct： 在使用MySQL时，有时需要查询出某个字段不重复的记录，这时可以使用mysql提供的distinct这个关键字来过滤重复的记录。 limit字句： Limit子句可以被用于强制 SELECT 语句返回指定的记录数。Limit接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。12345678//初始记录行的偏移量是 0(而不是 1)：mysql&gt; SELECT * FROM table LIMIT 5,10; //检索记录行6-15//为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：mysql&gt; SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last//如果只给定一个参数，它表示返回最大的记录行数目。换句话说，LIMIT n 等价于 LIMIT 0,n：mysql&gt; SELECT * FROM table LIMIT 5; //检索前 5 个记录行 查找各个部门当前(to_date=’9999-01-01’)领导当前薪水详情以及其对应部门编号dept_no123456789101112CREATE TABLE `dept_manager` ( `dept_no` char(4) NOT NULL, `emp_no` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`)); CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`)); 123select salaries.*, dept_manager.dept_no from salaries inner join dept_manager on salaries.emp_no=dept_manager.emp_no and salaries.to_date='9999-01-01' and dept_manager.to_date='9999-01-01'; 使用多表查询或连接查询，根据要求，确定salaries表为主表，使用inner join进行连接，连接条件为emp_no字段相同，在加入where字句筛选to_date=’9999-01-01’。 查找所有已经分配部门的员工的last_name和first_name1234567891011121314CREATE TABLE `dept_emp` ( `emp_no` int(11) NOT NULL, `dept_no` char(4) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `employees` ( `emp_no` int(11) NOT NULL, `birth_date` date NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` char(1) NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`)); 1select e.last_name, e.first_name, d.dept_no from employees e inner join dept_emp d on e.emp_no = d.emp_no 因为要查找所有已分配部门的员工信息，所以两表中都存在的emp_no才是所要查询的目标，因此使用inner join。 查找所有员工的last_name和first_name以及对应部门编号dept_no，也包括展示没有分配具体部门的员工1select e.last_name, e.first_name, d.dept_no from employees e left outer join dept_emp d on e.emp_no = d.emp_no 因为要查找所有员工信息，所以左表中所有的emp_no都要包含，因此使用left outer join。 查找所有员工入职时候的薪水情况，给出emp_no以及salary， 并按照emp_no进行逆序 1234567891011121314CREATE TABLE `employees` ( `emp_no` int(11) NOT NULL, `birth_date` date NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` char(1) NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`));CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`)); 123select e.emp_no, s.salary from employees e inner join salaries son s.emp_no = e.emp_no and s.from_date = e.hire_dateorder by e.emp_no desc 由于测试数据中，salaries.emp_no 不唯一（因为号码为 emp_no 的员工会有多次涨薪的可能，所以在 salaries 中对应的记录不止一条），而employees.emp_no 唯一，即 salaries 的数据会多于 employees，因此需先找到 employees.emp_no 在 salaries 表中对应的记录salaries.emp_no，则有限制条件 e.emp_no = s.emp_no 根据题意注意到 salaries.from_date 和 employees.hire_date 的值应该要相等，因此有限制条件 e.hire_date = s.from_date 根据题意要按照 emp_no 值逆序排列，因此最后要加上 ORDER BY e.emp_no DESC 查找薪水涨幅超过15次的员工号emp_no以及其对应的涨幅次数t 123456CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`)); 1select emp_no, count(emp_no) t from salaries group by emp_no having t&gt;15 用COUNT()函数和GROUP BY语句可以统计同一emp_no值的记录条数 根据题意，输出的涨幅次数为t，故用AS语句将COUNT(emp_no)的值转换为t (AS可省略) 由于COUNT()函数不可用于WHERE语句中，故使用HAVING语句来限定t&gt;15的条件 having子句： having字句可以让我们筛选成组后的各种数据，where字句在聚合前先筛选记录，也就是说作用在group by和having字句前。而 having子句在聚合后对组记录进行筛选。我的理解就是真实表中没有此数据，这些数据是通过一些函数生存。 找出所有员工当前(to_date=’9999-01-01’)具体的薪水salary情况，对于相同的薪水只显示一次,并按照逆序显示123select distinct salary from salaries where to_date='9999-01-01' order by salary desc或select salary from salaries where to_date='9999-01-01' group by salary order by salary desc 相同薪水显示一次，使用SELECT DISTINCT可去除重复值，但是大表一般用distinct效率不高，大数据量的时候都禁止用distinct，可以用group by解决重复问题。 获取所有部门当前manager的当前薪水情况，给出dept_no, emp_no以及salary，当前表示to_date=’9999-01-01’ 123456789101112CREATE TABLE `dept_manager` ( `dept_no` char(4) NOT NULL, `emp_no` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `salaries` ( `emp_no` int(11) NOT NULL, `salary` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`from_date`)); 12345SELECT d.dept_no, d.emp_no, s.salary FROM salaries AS s INNER JOIN dept_manager AS d ON d.emp_no = s.emp_noAND d.to_date = '9999-01-01'AND s.to_date = '9999-01-01' 先用INNER JOIN连接两张表，限制条件是两张表的emp_no相同，即d.emp_no = s.emp_no，并且将salaries用别名s代替，dept_manager用别名d代替 根据题意，要获取当前manager的当前salary情况，再加上限制条件d.to_date = ‘9999-01-01’ AND s.to_date = ‘9999-01-01’即可（因为同一emp_no在salaries表中对应多条涨薪记录，而当s.to_date = ‘9999-01-01’时是该员工当前的薪水记录） 获取所有非manager的员工emp_no1234567891011121314CREATE TABLE `dept_manager` ( `dept_no` char(4) NOT NULL, `emp_no` int(11) NOT NULL, `from_date` date NOT NULL, `to_date` date NOT NULL, PRIMARY KEY (`emp_no`,`dept_no`));CREATE TABLE `employees` ( `emp_no` int(11) NOT NULL, `birth_date` date NOT NULL, `first_name` varchar(14) NOT NULL, `last_name` varchar(16) NOT NULL, `gender` char(1) NOT NULL, `hire_date` date NOT NULL, PRIMARY KEY (`emp_no`)); 方法1：SQL支持集合运算 – EXPECT 集合差运算 – UNION 集合并运算 – INTERSECT 集合交运算 123select e.emp_no from employees e EXCEPTselect d.emp_no from dept_manager d 方法2：使用NOT IN选出在employees但不在dept_manager中的emp_no记录 12SELECT emp_no FROM employeesWHERE emp_no NOT IN (SELECT emp_no FROM dept_manager) 方法3：先使用LEFT JOIN连接两张表，再从此表中选出dept_no值为NULL对应的emp_no记录 123SELECT employees.emp_no FROM employees LEFT JOIN dept_managerON employees.emp_no = dept_manager.emp_noWHERE dept_no IS NULL]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL查询语句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8的集合4：LinkedHashMap的实现原理]]></title>
    <url>%2F2019%2F05%2F06%2FJava8%E7%9A%84%E9%9B%86%E5%90%884%EF%BC%9ALinkedHashMap%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[概述按照惯例，先看一下源码里的第一段注释： Hash table and linked list implementation of the Map interface, with predictable iteration order. This implementation differs from HashMap in that it maintains a doubly-linked list running through all of its entries. This linked list defines the iteration ordering, which is normally the order in which keys were inserted into the map (insertion-order). Note that insertion order is not affected if a key is re-inserted into the map. (A key k is reinserted into a map m if m.put(k, v) is invoked when m.containsKey(k) would return true immediately prior to the invocation.) 从注释中，我们可以先了解到LinkedHashMap是通过哈希表和链表实现的，它通过维护一个链表来保证对哈希表迭代时的有序性，而这个有序是指键值对插入的顺序。另外，当向哈希表中重复插入某个键的时候，不会影响到原来的有序性。也就是说，假设你插入的键的顺序为1、2、3、4，后来再次插入2，迭代时的顺序还是1、2、3、4，而不会因为后来插入的2变成1、3、4、2。（但其实我们可以改变它的规则，使它变成1、3、4、2） LinkedHashMap的实现主要分两部分，一部分是哈希表，另外一部分是链表。哈希表部分继承了HashMap，拥有了HashMap那一套高效的操作，LinkedHashMap中链表的部分，通过一个双向链表，按序存储HashMap的每个键值对，借此来维护有序性。 属性LinkedHashMap 是继承自 HashMap 的，所以它已经从 HashMap 那里继承了与哈希表相关的操作了，那么在 LinkedHashMap 中，它可以专注于链表实现的那部分，所以与链表实现相关的属性如下。1234567891011121314151617//LinkedHashMap的链表节点继承了HashMap的节点，而且每个节点都包含了前指针和后指针，所以这里可以看出它是一个双向链表static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125;//头指针transient LinkedHashMap.Entry&lt;K,V&gt; head;//尾指针transient LinkedHashMap.Entry&lt;K,V&gt; tail;//默认为false。当为true时，表示链表中键值对的顺序与每个键的插入顺序一致，也就是说重复插入键，也会更新顺序//简单来说，为false时，就是上面所指的1、2、3、4的情况；为true时，就是1、3、4、2的情况final boolean accessOrder; 方法在HashMap的源码中，我们可以发现，HashMap中有如下三个方法：1234567// Callbacks to allow LinkedHashMap post-actionsvoid afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; 这三个方法表示的是在访问、插入、删除某个节点之后，进行一些处理，它们在LinkedHashMap都有各自的实现。LinkedHashMap正是通过重写这三个方法来保证链表的插入、删除的有序性。 afterNodeAccess方法改方法就是把当前节点e移至链表的尾部。因为使用的是双向链表，所以在尾部插入可以以O（1）的时间复杂度来完成。并且只有当accessOrder设置为true时，才会执行这个操作。在HashMap的putVal方法中，就调用了这个方法。 afterNodeInsertion方法1234567void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; afterNodeInsertion方法是在哈希表中插入了一个新节点时调用的，它会把链表的头节点删除掉，删除的方式是通过调用HashMap的removeNode方法。通过afterNodeInsertion方法和afterNodeAccess方法，就可以简单的实现一个基于最近最少使用（LRU）的淘汰策略。当然，我们还要重写removeEldestEntry方法，因为它默认返回的是false。 afterNodeRemoval方法这个方法是当HashMap删除一个键值对时调用的，它会把在HashMap中删除的那个键值对一并从链表中删除，保证了哈希表和链表的一致性。 get方法LinkedHashMap的get方法调用的是HashMap的getNode方法来获取结果的。并且，如果你把accessOrder设置为true，那么在获取到值之后，还会调用afterNodeAccess方法。这样就能保证一个LRU的算法。 put和remove方法LinkedHashMap的源码中没有找到put方法，这就说明了它并没有重写put方法，所以我们调用的put方法其实是HashMap的put方法。因为HashMap的put方法中调用了afterNodeAccess方法和afterNodeInsertion方法，已经足够保证链表的有序性了，所以它也就没有重写put方法了。remove方法也是如此。 总结 LinkedHashMap是继承于HashMap，是基于HashMap和双向链表来实现的。 HashMap无序；LinkedHashMap有序，可分为插入顺序和访问顺序两种。如果是访问顺序（accessOrder=true），那put和get操作已存在的Entry时，都会把Entry移动到双向链表的表尾(其实是先删除再插入)。 LinkedHashMap存取数据，还是跟HashMap一样使用的Entry[]的方式，双向链表只是为了保证顺序。 LinkedHashMap是线程不安全的。]]></content>
      <categories>
        <category>JAVA集合</category>
      </categories>
      <tags>
        <tag>LinkedHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8的集合3：HashMap的实现原理]]></title>
    <url>%2F2019%2F05%2F05%2FJava8%E7%9A%84%E9%9B%86%E5%90%883%EF%BC%9AHashMap%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[概述一上来，先来看看源码中的这一段注释，我们可以从中提取到一些关键信息：Hash table based implementation of the Map interface. This implementation provides all of the optional map operations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.) This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time.翻译一下大概就是在说，这个哈希表是基于Map接口的实现的，它允许null值和null键，它不是线程同步的，同时也不保证有序。This implementation provides constant-time performance for the basic operations (get and put), assuming the hash function disperses the elements properly among the buckets. Iteration over collection views requires time proportional to the “capacity” of the HashMap instance (the number of buckets) plus its size (the number of key-value mappings). Thus, it’s very important not to set the initial capacity too high (or the load factor too low) if iteration performance is important. An instance of HashMap has two parameters that affect its performance: initial capacity and load factor. The capacity is the number of buckets in the hash table, and the initial capacity is simply the capacity at the time the hash table is created. The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased. When the number of entries in the hash table exceeds the product of the load factor and the current capacity, the hash table is rehashed (that is, internal data structures are rebuilt) so that the hash table has approximately twice the number of buckets.再来看看这一段，讲的是Map的这种实现方式为get（取）和put（存）带来了比较好的性能。但是如果涉及到大量的遍历操作的话，就尽量不要把capacity设置得太高（或load factor设置得太低），否则会严重降低遍历的效率。影响HashMap性能的两个重要参数：“initial capacity”（初始化容量）和”load factor“（负载因子）。简单来说，容量就是哈希表桶的个数，负载因子就是键值对个数与哈希表长度的一个比值，当比值超过负载因子之后，HashMap就会进行rehash操作来进行扩容。HashMap 的大致结构如下，其中哈希表是一个数组，我们经常把数组中的每一个节点称为一个桶，哈希表中的每个节点都用来存储一个键值对。在插入元素时，如果发生冲突（即多个键值对映射到同一个桶上）的话，就会通过链表的形式来解决冲突。因为一个桶上可能存在多个键值对，所以在查找的时候，会先通过key的哈希值先定位到桶，再遍历桶上的所有键值对，找出key相等的键值对，从而来获取value。 属性12345678910111213141516171819202122//默认的初始容量为16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;//最大的容量上限为2^30static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认的负载因子为0.75static final float DEFAULT_LOAD_FACTOR = 0.75f;//变成树型结构的临界值为8static final int TREEIFY_THRESHOLD = 8;//恢复链式结构的临界值为6static final int UNTREEIFY_THRESHOLD = 6;//哈希表transient Node&lt;K,V&gt;[] table;//哈希表中键值对的个数transient int size;//哈希表被修改的次数transient int modCount;//它是通过capacity*load factor计算出来的，当size到达这个值时，就会进行扩容操作int threshold;//负载因子final float loadFactor;//当哈希表的大小超过这个阈值，才会把链式结构转化成树型结构，否则仅采取扩容来尝试减少冲突static final int MIN_TREEIFY_CAPACITY = 64; 下面是 Node 类的定义，它是 HashMap 中的一个静态内部类，哈希表中的每一个节点都是 Node 类型。我们可以看到，Node 类中有 4 个属性，其中除了 key 和 value 之外，还有 hash 和 next 两个属性。hash 是用来存储 key 的哈希值的，next 是在构建链表时用来指向后继节点的。123456static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next;&#125; 方法get方法实现步骤大致如下： 通过hash值获取该key映射到的桶。 桶上的key就是要查找的key，则直接命中。 桶上的key不是要查找的key，则查看后续节点： （1）如果后续节点是树节点，通过调用树的方法查找该key。 （2）如果后续节点是链式节点，则通过循环遍历链查找该key。put方法put方法比较复杂，实现步骤大致如下： 先通过hash值计算出key映射到哪个桶。 如果桶上没有碰撞冲突，则直接插入。 如果出现碰撞冲突了，则需要处理冲突： （1）如果该桶使用红黑树处理冲突，则调用红黑树的方法插入。 （2）否则采用传统的链式方法插入。如果链的长度到达临界值，则把链转变为红黑树。. . 如果桶中存在重复的键，则为该键替换新值。 如果size大于阈值，则进行扩容。remove方法理解了put方法之后，remove已经没什么难度了，所以重复的内容就不再做详细介绍了。hash方法在get方法和put方法中都需要先计算key映射到哪个桶上，然后才进行之后的操作，计算的主要代码如下：1(n - 1) &amp; hash 上面代码中的n指的是哈希表的大小，hash指的是key的哈希值，hash是通过下面这个方法计算出来的，采用了二次哈希的方式，其中key的hashCode方法是一个native方法：1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这个hash方法先通过key的hashCode方法获取一个哈希值，再拿这个哈希值与它的高16位的哈希值做一个异或操作来得到最后的哈希值。 为啥要这样做呢？注释中是这样解释的：如果当n很小，假设为64的话，那么n-1即为63（0x111111），这样的值跟hashCode()直接做与操作，实际上只使用了哈希值的后6位。如果当哈希值的高位变化很大，低位变化很小，这样就很容易造成冲突了，所以这里把高低位都利用起来，从而解决了这个问题。 正是因为与的这个操作，决定了HashMap的大小只能是2的幂次方，想一想，如果不是2的幂次方，会发生什么事情？即使你在创建HashMap的时候指定了初始大小，HashMap在构建的时候也会调用下面这个方法来调整大小：123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 这个方法的作用看起来可能不是很直观，它的实际作用就是把cap变成第一个大于等于2的幂次方的数。例如，16还是16，13就会调整为16，17就会调整为32。 resize方法HashMap在进行扩容时，使用的rehash方式非常巧妙，因为每次扩容都是翻倍，与原来计算（n-1）&amp;hash的结果相比，只是多了一个bit位，所以节点要么就在原来的位置，要么就被分配到“原位置+旧容量”这个位置。 例如，原来的容量为32，那么应该拿hash跟31（0x11111）做与操作；在扩容扩到了64的容量之后，应该拿hash跟63（0x111111）做与操作。新容量跟原来相比只是多了一个bit位，假设原来的位置在23，那么当新增的那个bit位的计算结果为0时，那么该节点还是在23；相反，计算结果为1时，则该节点会被分配到23+31的桶上。 正是因为这样巧妙的rehash方式，保证了rehash之后每个桶上的节点数必定小于等于原来桶上的节点数，即保证了rehash之后不会出现更严重的冲突。 在这里有一个需要注意的地方，有些文章指出当哈希表的桶占用超过阈值时就进行扩容，这是不对的；实际上是当哈希表中的键值对个数超过阈值时，才进行扩容的。 总结 通过红黑树的方式来处理哈希冲突是我第一次看见！学过哈希，学过红黑树，就是从来没想到两个可以结合到一起这么用！ 按照原来的拉链法来解决冲突，如果一个桶上的冲突很严重的话，是会导致哈希表的效率降低至O（n），而通过红黑树的方式，可以把效率改进至O（logn）。相比链式结构的节点，树型结构的节点会占用比较多的空间，所以这是一种以空间换时间的改进方式。]]></content>
      <categories>
        <category>JAVA集合</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8的集合2：HashSet的实现原理]]></title>
    <url>%2F2019%2F05%2F05%2FJava8%E7%9A%84%E9%9B%86%E5%90%882%EF%BC%9AHashSet%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[概述HashSet是Set接口的典型实现，HashSet按照Hash算法来存储集合中的元素。存在以下特点： 不能保证元素的顺序，元素是无序的 HashSet不是同步的，需要外部保持线程之间的同步问题 集合元素值允许为null数据结构1234java.lang.Object java.util.AbstractCollection&lt;E&gt; java.util.AbstractSet&lt;E&gt; java.util.HashSet&lt;E&gt; 继承关系，实现接口1Serializable, Cloneable, Iterable&lt;E&gt;, Collection&lt;E&gt;, Set&lt;E&gt; 基本属性12private transient HashMap&lt;E,Object&gt; map; //map集合，HashSet存放元素的容器private static final Object PRESENT = new Object(); //map，中键对应的value值 方法构造方法123456789101112131415161718192021//无参构造方法，完成map的创建public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;//指定集合转化为HashSet, 完成map的创建public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;//指定初始化大小，和负载因子public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;//指定初始化大小public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;//指定初始化大小和负载因子，dummy 无实际意义HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 通过构造函数，不难发现，HashSet的底层是采用HashMap实现的。 add()方法123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; PRESENT为HashSet类中定义的一个常量，并无实际的意义，HashSet的add()方法调用HashMap的put()方法实现，如果键已经存在，HashMap.put()放回的是旧值，添加失败；如果添加成功，map.put()方法返回的值为null ，HashSet.add()方法返回true。 要添加的元素为map中的key 。 remove()方法123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 删除方法，调用map.remove()方法实现，若map.remove()能找到指定的key,则返回key对应的value。 对于Hashset而言，它所有的key对应的值都是PRESENT。完整源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable&#123; static final long serialVersionUID = -5024744406713321676L; //序列化版本号 private transient HashMap&lt;E,Object&gt; map; //HashMap变量，用于存放HashSet的值 private static final Object PRESENT = new Object(); //map中的值 //构造方法 public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; //构造方法，将指定的集合转化为HashSet public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125; //构造方法，指定初始化的大小和负载因子 public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor); &#125; //指定初始化大小 public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity); &#125; //构造方法，采用default修饰，只能是同一个包下的成员访问。包不相同无法访问 HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; //HashSet的遍历操作 //通过这个方法可以发现，HashSet调用了HashMap存放，因为HashSet并不是键值对存储，所以它只是把它的值做了Map中的键，在遍历HashSet的集合元素时，实际上是遍历的Map中Key的集合。 public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125; //返回集合中元素的容量 public int size() &#123; return map.size(); &#125; //判断是否为空 public boolean isEmpty() &#123; return map.isEmpty(); &#125; //是否包含指定的元素 public boolean contains(Object o) &#123; return map.containsKey(o); &#125; //添加元素，添加的元素作为了Map中的key,value使用了一个常量表示 public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; //删除元素 public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125; //清空集合 public void clear() &#123; map.clear(); &#125; //克隆方法 public Object clone() &#123; try &#123; HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone(); newSet.map = (HashMap&lt;E, Object&gt;) map.clone(); return newSet; &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(); &#125; &#125; //写入输出流操作。 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; // Write out any hidden serialization magic s.defaultWriteObject(); // Write out HashMap capacity and load factor s.writeInt(map.capacity()); s.writeFloat(map.loadFactor()); // Write out size s.writeInt(map.size()); // Write out all elements in the proper order. for (E e : map.keySet()) s.writeObject(e); &#125; //从输入流中读取对象 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in any hidden serialization magic s.defaultReadObject(); // Read in HashMap capacity and load factor and create backing HashMap int capacity = s.readInt(); float loadFactor = s.readFloat(); map = (((HashSet)this) instanceof LinkedHashSet ? new LinkedHashMap&lt;E,Object&gt;(capacity, loadFactor) : new HashMap&lt;E,Object&gt;(capacity, loadFactor)); // Read in size int size = s.readInt(); // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; E e = (E) s.readObject(); map.put(e, PRESENT); &#125; &#125;&#125; 总结 静下心来仔细研究了一下，发现hashset是通过将相应的内容存储在了一个hashmap里的key中，然后再去读取的。为了保证hashset里面的数据唯一性，这里将hashset存放的元素作为了hashmap里面唯一的key变量，value部分用一个PRESENT对象来存储，也就是源码里面的这一句内容： 1private static final Object PRESENT = new Object(); HashSet的底层通过HashMap实现的，而HashMap在1.7之前使用的是数组+链表实现，在1.8+使用的数组+链表+红黑树实现。其实也可以这样理解，HashSet的底层实现和HashMap使用的是相同的方式，因为Map是无序的，因此HashSet也无法保证顺序。HashSet的方法也是借助HashMap的方法来实现的。]]></content>
      <categories>
        <category>JAVA集合</category>
      </categories>
      <tags>
        <tag>HashSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8的集合1：ArrayList的实现原理]]></title>
    <url>%2F2019%2F04%2F28%2FJava8%E7%9A%84%E9%9B%86%E5%90%881%EF%BC%9AArrayList%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[概述：一上来，先来看看源码中的这一段注释，我们可以从中提取到一些关键信息：Resizable-array implementation of the List interface. Implements all optional list operations, and permits all elements, including null. In addition to implementing the List interface, this class provides methods to manipulate the size of the array that is used internally to store the list. (This class is roughly equivalent to Vector, except that it is unsynchronized.)从这段注释中，我们可以得知ArrayList是一个动态数组，实现了List接口以及list相关的所有方法，它允许所有元素的插入，包括null。另外，ArrayList和Vector除了线程不同步之外，大致相等。 属性1234567891011121314151617//默认容量的大小private static final int DEFAULT_CAPACITY = 10;//空数组常量private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//默认的空数组常量private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//存放元素的数组，从这可以发现ArrayList的底层实现就是一个Object数组transient Object[] elementData;//数组中包含的元素个数private int size;//数组的最大上限private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; ArrayList的属性非常少，就只有这些。其中最重要的莫过于elementData了，ArrayList所有的方法都是建立在elementData之上。接下来，我们就来看一下一些主要的方法。 方法构造方法123456789101112public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+initialCapacity); &#125;&#125;public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 从构造方法中我们可以看见，默认情况下，elementData是一个大小为0的空数组，当我们指定了初始大小的时候，elementData的初始大小就变成了我们所指定的初始大小了。 get方法1234567891011public E get(int index) &#123; rangeCheck(index); return elementData(index);&#125;private void rangeCheck(int index) &#123; if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;E elementData(int index) &#123; return (E) elementData[index];&#125; 因为ArrayList是采用数组结构来存储的，所以它的get方法非常简单，先是判断一下有没有越界，之后就可以直接通过数组下标来获取元素了，所以get的时间复杂度是O(1) add方法123456789101112131415161718192021222324public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //调用一个native的复制方法，把index位置开始的元素都往后挪一位 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; ArrayList的add方法也很好理解，在插入元素之前，它会先检查是否需要扩容，然后再把元素添加到数组中最后一个元素的后面。在ensureCapacityInternal方法中，我们可以看见，如果当elementData为空数组时，它会使用默认的大小去扩容。所以说，通过无参构造方法来创建ArrayList时，它的大小其实是为0的，只有在使用到的时候，才会通过grow方法去创建一个大小为10的数组。 第一个add方法的复杂度为O(1)，虽然有时候会涉及到扩容的操作，但是扩容的次数是非常少的，所以这一部分的时间可以忽略不计。如果使用的是带指定下标的add方法，则复杂度为O(n)，因为涉及到对数组中元素的移动，这一操作是非常耗时的。 set方法123456public E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; set方法的作用是把下标为index的元素替换成element，跟get非常类似，所以就不在赘述了，时间复杂度度为O(1)。 remove方法12345678910public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; remove方法与add带指定下标的方法非常类似，也是调用系统的arraycopy方法来移动元素，时间复杂度为O(n)。 grow方法 1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; grow方法是在数组进行扩容的时候用到的，从中我们可以看见，ArrayList每次扩容都是扩1.5倍，然后调用Arrays类的copyOf方法，把元素重新拷贝到一个新的数组中去。 size方法 123public int size() &#123; return size;&#125; size方法非常简单，它是直接返回size的值，也就是返回数组中元素的个数，时间复杂度为O(1)。这里要注意一下，返回的并不是数组的实际大小。 indexOf方法和lastIndexOf 123456789101112131415161718192021222324public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; indexOf方法的作用是返回第一个等于给定元素的值的下标。它是通过遍历比较数组中每个元素的值来查找的，所以它的时间复杂度是O(n)。 lastIndexOf的原理跟indexOf一样，而它仅仅是从后往前找起罢了。 VectorVector的很多方法都跟ArrayList一样，只是多加了个synchronized来保证线程安全。所以只把Vector与ArrayList的不同点提一下就可以了。 Vector比ArrayList多了一个属性：1protected int capacityIncrement; 这个属性是在扩容的时候用到的，它表示每次扩容只扩capacityIncrement个空间就足够了。该属性可以通过构造方法给它赋值。先来看一下构造方法： 12345678910111213public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement;&#125;public Vector(int initialCapacity) &#123; this(initialCapacity, 0);&#125;public Vector() &#123; this(10);&#125; 从构造方法中，我们可以看出Vector的默认大小也是10，而且它在初始化的时候就已经创建了数组了，这点跟ArrayList不一样。 再来看一下grow方法：12345678910private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125; 从grow方法中我们可以发现，newCapacity默认情况下是两倍的oldCapacity，而当指定了capacityIncrement的值之后，newCapacity变成了oldCapacity+capacityIncrement。 总结 ArrayList创建时的大小为0；当加入第一个元素时，进行第一次扩容时，默认容量大小为10。 ArrayList每次扩容都以当前数组大小的1.5倍去扩容。 Vector创建时的默认大小为10。 Vector每次扩容都以当前数组大小的2倍去扩容。当指定了capacityIncrement之后，每次扩容仅在原先基础上增加capacityIncrement个单位空间。 ArrayList和Vector的add、get、size方法的复杂度都为O(1)，remove方法的复杂度为O(n)。 ArrayList是非线程安全的，Vector是线程安全的。]]></content>
      <categories>
        <category>JAVA集合</category>
      </categories>
      <tags>
        <tag>ArrayList</tag>
        <tag>Vector</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java：CAS]]></title>
    <url>%2F2019%2F04%2F26%2FJava%EF%BC%9ACAS%2F</url>
    <content type="text"><![CDATA[悲观锁和乐观锁 什么是悲观锁、乐观锁？在java语言里，总有一些名词看语义跟本不明白是啥玩意儿，也就总有部分面试官拿着这样的词来忽悠面试者，以此来找优越感，其实理解清楚了，这些词也就唬不住人了。 synchronized 是悲观锁，这种线程一旦得到锁，其他需要锁的线程就挂起的情况就是悲观锁。 CAS 操作的就是乐观锁，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。 从思想上来说，Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。线程安全 在进入正题之前，我们先理解下下面的代码:12345678910111213141516171819202122232425private static int count = 0; public static void main(String[] args) &#123; for (int i = 0; i &lt; 2; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //每个线程让count自增100次 for (int i = 0; i &lt; 100; i++) &#123; count++; &#125; &#125; &#125;).start(); &#125; try&#123; Thread.sleep(2000); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; System.out.println(count); &#125; 请问cout的输出值是否为200？答案是否定的，因为这个程序是线程不安全的，所以造成的结果count值可能小于200。 那么如何改造成线程安全的呢，其实我们可以使用上Synchronized同步锁,我们只需要在count++的位置添加同步锁，代码如下:123456789101112131415161718192021222324252627private static int count = 0; public static void main(String[] args) &#123; for (int i = 0; i &lt; 2; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //每个线程让count自增100次 for (int i = 0; i &lt; 100; i++) &#123; synchronized (ThreadCas.class)&#123; count++; &#125; &#125; &#125; &#125;).start(); &#125; try&#123; Thread.sleep(2000); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; System.out.println(count); &#125; 加了同步锁之后，count自增的操作变成了原子性操作，所以最终的输出一定是count=200，代码实现了线程安全。 但是Synchronized虽然确保了线程的安全，但是在性能上却不是最优的，Synchronized关键字会让没有得到锁资源的线程进入BLOCKED状态，而后在争夺到锁资源后恢复为RUNNABLE状态，这个过程中涉及到操作系统用户模式和内核模式的转换，代价比较高。 因此，在JAVA中改用原子类操作加以改进。所谓原子操作类，指的是java.util.concurrent.atomic包下，一系列以Atomic开头的包装类。例如AtomicBoolean，AtomicInteger，AtomicLong。它们分别用于Boolean，Integer，Long类型的原子性操作。123456789101112131415161718192021222324252627private static AtomicInteger count = new AtomicInteger(0);public static void main(String[] args) &#123; for (int i = 0; i &lt; 2; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //每个线程让count自增100次 for (int i = 0; i &lt; 100; i++) &#123; count.incrementAndGet(); &#125; &#125; &#125;).start(); &#125; try&#123; Thread.sleep(2000); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; System.out.println(count);&#125; 使用AtomicInteger之后，最终的输出结果同样可以保证是200。并且在某些情况下，代码的性能会比Synchronized更好。而Atomic操作的底层实现正是利用的CAS机制。 JMM 想要理解CAS，首先先要了解下JMM。 JMM：Java内存模型，是一种抽象的概念，可以理解为一组规范。 JMM的特性：可见性，原子性，有序性。 JMM关于同步的规定： 线程解锁前必须将共享变量的值刷新回主内存。 线程加锁前必须读主内存的最新值到自己的工作内存中。 加锁解锁是同一把锁。 线程间的通信（传值）必须通过主内存。 什么是CAS？ 在计算机科学中，比较并交换（Conmpare And Swap）是用于实现多线程同步的原子指令。 它将内存位置的内容与给定值进行比较，只有在相同的情况下，将该内存位置的内容修改为新的给定值。 这是作为单个原子操作完成的。 原子性保证新值基于最新信息计算; 如果该值在同一时间被另一个线程更新，则写入将失败。 操作结果必须说明是否进行替换; 这可以通过一个简单的布尔响应（这个变体通常称为比较和设置），或通过返回从内存位置读取的值来完成（摘自维基本科）。 CAS的思想很简单：三个参数，一个当前内存值V、旧的预期值A、即将更新的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。 使用 compareAndSet方法将内存中的值5进行修改，第一次修改成功，内存中的值被改为2019，第二次进行比较时，由于内存中的值已经被修改，所以操作失败。123456public static void main(String[] args) &#123; AtomicInteger atomicInteger = new AtomicInteger(5); //main do something System.out.println(atomicInteger.compareAndSet(5,2019)+"\t current data: "+atomicInteger.get()); System.out.println(atomicInteger.compareAndSet(5,1024)+"\t current data: "+atomicInteger.get()); &#125; CAS的缺点 CPU开销较大：在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。 不能保证代码块的原子性CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3个变量共同进行原子性的更新，就不得不使用Synchronized了。 可能会出现ABA问题。 ABA问题 什么是ABA问题？简单来说一句话：狸猫换太子。举个例子：如线程1从内存X中取出A，这时候另一个线程2也从内存X中取出A，并且线程2进行了一些操作将内存X中的值变成了B，然后线程2又将内存X中的数据变成A，这时候线程1进行CAS操作发现内存X中仍然是A，然后线程1操作成功。虽然线程1的CAS操作成功，但是整个过程就是有问题的。比如链表的头在变化了两次后恢复了原值，但是不代表链表就没有变化。 如何解决：JAVA中提供了AtomicStampedReference来处理会发生ABA问题的场景，主要是在对象中额外再增加一个标记来标识对象是否有过变更（类似于GitHub的版本号）。 测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100);static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100,1);public static void main(String[] args) &#123; System.out.println("=============以下是ABA问题的产生============="); new Thread(()-&gt;&#123; atomicReference.compareAndSet(100,101); atomicReference.compareAndSet(101,100); &#125;,"t1").start(); new Thread(()-&gt;&#123; try &#123; //暂停1S线程2，保证线程1完成ABA操作 TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(atomicReference.compareAndSet(100,2019)+"\t"+atomicReference.get()); &#125;,"t2").start(); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("=============以下是ABA问题的解决============="); new Thread(()-&gt;&#123; int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName()+"\t第一次版本号： "+stamp); try &#123; //暂停1S线程3 TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(atomicStampedReference.compareAndSet(100,101, atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1)); System.out.println(Thread.currentThread().getName()+"\t第二次版本号： "+atomicStampedReference.getStamp()); System.out.println(atomicStampedReference.compareAndSet(101,100, atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1)); System.out.println(Thread.currentThread().getName()+"\t第三次版本号： "+atomicStampedReference.getStamp()); &#125;,"t3").start(); new Thread(()-&gt;&#123; int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName()+"\t第一次版本号： "+stamp); try &#123; //暂停3S线程4，保证线程3完成ABA操作 TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean result = atomicStampedReference.compareAndSet(100,2019,stamp,stamp+1); System.out.println(Thread.currentThread().getName()+"\t修改成功否： "+result+"\t 当前最新实际版本号： "+atomicStampedReference.getStamp()); System.out.println(Thread.currentThread().getName()+"\t当前实际最新值： "+atomicStampedReference.getReference()); &#125;,"t4").start();&#125; 输出结果：1234567891011=============以下是ABA问题的产生=============true 2019=============以下是ABA问题的解决=============t3 第一次版本号： 1t4 第一次版本号： 1truet3 第二次版本号： 2truet3 第三次版本号： 3t4 修改成功否： false 当前最新实际版本号： 3t4 当前实际最新值： 100]]></content>
      <categories>
        <category>JAVA_CAS</category>
      </categories>
      <tags>
        <tag>JAVA_CAS</tag>
        <tag>ABA问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github+Hexo搭建个人博客]]></title>
    <url>%2F2019%2F04%2F25%2FGithub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[准备环境 安装 Node 安装 Git 注册 GitHub 安装 Hexo 11 npm install hexo-cli -g 搭建本地个人博客 初始化 hexo 新建一个空白文件夹（下文提到的“项目根目录”是指你新建的文件夹的位置）用于存放 hexo 资源。在空白文件夹里面打开 Git Bash ，输入下列命令行进行初始化。 11 hexo init 生成静态页面11 hexo g 启动本地服务11 hexo s 关闭本地服务器在 Git Bash 界面按 Ctrl+C， 在浏览器输入：http://localhost:4000 查看 美化个人博客 博客主题设置克隆主题 在项目根目录下的 themes 文件中，打开 Git Bash ，用命令行克隆下新的主题。我这里用的 Next 主题，需要其他主题的自己百度找。 11 git clone https://github.com/theme-next/hexo-theme-next.git 配置主题 用文本的方式打开项目根目录下的 _config.yml 配置文件，找到 theme 把原来默认的 landscape 主题名字，改成刚刚克隆的主题名字。 测试主题 重新回到项目根目录下，打开 Git Bath ，用命令行启动服务器。在浏览器访问 http://localhost:4000 发布文章 方法一：在项目根目录下，打开 Git Bash ，执行新建命令，然后 hexo 会自动在指定目录下生成对应文件，如下图所示。然后找到新建好的文件，打开即可进行编辑。 11 hexo new "此处输入文章名字" 方法二：可以直接把已经准备的 md 格式的文章复制到 项目名称 /source/_posts 目录下，然后打开文件，在文件头加入 front-matter 部分，title 表示文章标题，date 表示发布时间。如图所示，图片上用到的其他参数，后面会介绍到。 重要的事情说三遍！！！ front-matte 书写的时候要注意，冒号后面要跟一个空格号 front-matte 书写的时候要注意，冒号后面要跟一个空格号 front-matte 书写的时候要注意，冒号后面要跟一个空格号 12341 ---2 title: a3 date: 2019-04-25 21:27:134 --- 准备好 md 格式文件后，使用下面命令生成网站静态文件到默认设置的 public 文件夹，然后再启动本地服务器。 11 hexo g 主题风格设置 打开主题文件夹下的 _config.yml 配置文件（注意：这里要区别，不是項目根目录，主题文件夹的路径为：新建空白文件夹名称/themes/主题文件夹名称）。通过查找功能找到 Schemes 模块，修改为 Gemini 风格。如果喜欢其他风格可以自己修改。 刷新页面可以看到新风格的界面如下图所示:博客左侧栏设置 在上面的网站界面，可以发现网站的文字是英文，只要修改一下语言模式即可。打开根目录文件夹下的 _config.yml配置文件。找到 language，设置为 zh-CN。标题等其他参数的设置如下。可以对照效果图的具体位置，根据自己的实际需求进行修改。（注意：修改了项目根目录下的 _config.yml配置文件，需要重启部署项目后才能生效）分类设置添加分类列表 在项目根目录下，执行下面的命令行，新建分类页面，然后会在项目根目录下的 source 文件夹中新建一个 categories 文件夹。 11 hexo new page categories 打开 categories 文件夹中的 index.md 文件，添加 type 字段，设置为 “categories”。如下图所示。 123451 ---2 title: categories3 date: 2019-04-25 22:17:144 type: "categories"5 --- 接着到主题文件夹下的_config.yml 配置文件下，找到 menu 模块，把 categories 的注释给去掉。 刷新页面（如果刷新没效果，可以重启服务），可以在页面左侧栏上看到多了一个“分类”列表。如何将文章添加到对应分类？ 文章发布前，在 front-matter 部分，多写一个 categories 字段，然后参数写上类别的名称，保存后重启服务，在网页上点击“分类”，可以看到分类下已经生成了刚刚设置的类别，并把刚刚发布的文章归类在此类别下。如下图所示123451 ---2 title: "文章的标题"3 date: 2019-04-25 22:17:144 categories: "文章的分类"5 --- 标签设置 方法跟分类设置一样，所以不再赘述介绍 但是需要补充一点， front-matter 中字段有多个参数的时候，可以使用如下图的写法。1234567891011121 ---2 title: "文章的标题"3 date: 2019-04-25 22:17:144 categories: "文章的分类"5 tags: 6 -"标签1"7 -"标签2"8 -"标签3"9 description: "描述"10 photos: 11 -"链接"12 --- 博客添加站内搜索 NexT主题支持集成 Swiftype、 微搜索、Local Search 和 Algolia。下面介绍 Local Search 的安装吧。注意：安装的时候要是项目根目录下安装。 安装 hexo-generator-search 11 npm install hexo-generator-search --save 安装 hexo-generator-searchdb 11 npm install hexo-generator-searchdb --save 在项目根目录下的 _config.yml 配置文件的文末添加下面这段代码。 123451 search:2 path: search.xml3 field: post4 format: html5 limit: 10000 编辑主题文件夹的 _config.yml 配置文件，设置 Local searchenable 为 ture。 重启服务博客头像设置添加博客头像 打开主题文件夹下的 _config.yml 配置文件，通过查找功能找到 avatar，然后把一个在线的头像图片地址（百度图片中直接复制链接即可），作为 url 的参数。 然后刷新页面，可以看到网站上已经显示了相应的头像了。右上角 fork me 设置 在 GitHub Corners 上选择你喜欢的挂饰，复制方框内的代码。 打开主题文件夹下的 layout 文件夹，用记事本的方式打开 _layout.swig，把刚刚复制的代码放到下面，并把 href 的参数，修改为自己的 github 链接（放自己要跳转的网址即可）。 重启服务器，查看效果网页背景设置动态背景设置 打开主题文件夹下的 layout 文件夹，用文本的方式打开 _layout.swig 文件，在文末加上如下的代码：121 &lt;!-- 动态背景 --&gt;2 &lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt; 背景图片设置 打开主题文件夹下的 source 文件夹，进入 css/_custom 文件下，用文本形式打开 custom.styl 文件，然后添加下面这段代码。代码中 url 的地址是指到： 主题文件夹/source/images/ 。1234567891 body&#123;2 background:url(/images/bg.jpg);3 background-size:cover;4 background-repeat:no-repeat;5 background-attachment:fixed;6 background-position:center;7 // 设置主题部分的透明度，具体看图8 opacity: 0.8;9 &#125; 首页文章预览设置 默认情况下，文章在首页是全文显示的，这样肯定是不方便读者浏览。所以需要实现预览模式。 方法一：使用 &lt; !–more–&gt; 手动切断这种方法可以根据文章的内容，自己在合适的位置添加 &lt; !–more–&gt; 标签，使用灵活，也是Hexo推荐的方法。 方法二：添加 description在文章的 front-matter 中添加 description 和 photos 字段，如3.5图所示。如果不需要显示图片的话，可以把 photos 去掉。ps：不知道 front-matter 是什么的话，跳转到第二章的第4点的发布文章看下。 方法三：自动形成摘要在主题文件下的_config.yml 配置文件中添加默认截取的长度为 150 字符，可以根据需要自行设定。1231 auto_excerpt:2 enable: true3 length: 150 RSS 设置 安装 hexo 插件，需要在 hexo 项目根目录下进行安装。 11 npm install --save hexo-generator-feed 安装完成后在项目根目录下的 _config.yml 配置文件的文末添加下面这段代码： 1231 # Extentions2 ## Plugins: http://hexo.io/plugins/3 plugins: hexo-generator-feed 在主题文件夹下的 _config.yml 配置文件中，找到 rss ，在后面加上 /atom.xml。 重启服务，刷新页面社交小图标设置 在主题文件夹下的_config.yml 配置文件中，搜索 Social，然后提示自己增加自己需要的小图标并设置对应连接。 图标可以到 Font Awesome Icon 网站查找。友情链接设置 在主题文件夹下的 _config.yml 配置文件中，搜索 links_title，然后根据自己的需求自己吸修改。博客置顶设置 安装插件 121 npm uninstall hexo-generator-index --save2 npm install hexo-generator-index-pin-top --save 然后在需要置顶的文章的 Front-matter 中加上 top 即可，数值越大表示等级越高，越靠前显示。 123451 ---2 title: "文章的标题"3 date: 2019-04-25 22:17:144 top: 1005 --- 在主题文件夹中打开 layout/_macro/post.swig 文件，定位到 post-header ，把下面的代码添加进去即可。 12341 &#123;% if post.top %&#125;2 &lt;i class="fa fa-thumb-tack"&gt;&lt;/i&gt;3 &lt;font color=7D26CD&gt;置顶&lt;/font&gt;4 &#123;% endif %&#125; 对接Github的远程仓库 在Github创建一个公有仓库，并把公有仓库的链接保存下来。注意：仓库名字必须是：username.github.io，其中username是你的用户名。 打开项目根目录下的 _config.yml 配置文件，修改 deploy 的值。tpye 设置为 git，repo 则设置为刚刚新建的远程仓库链接。 注意：冒号后面需要再加一个空格，不然会出现格式错误。 安装hexo-deployer-gi 11 npm install hexo-deployer-git --save 一键部署到远程仓库 121 hexo g2 hexo deploy 回到刚刚新建的远程仓库，刷新页面，可以发现本地博客的相关文件已经全部部署到远程仓库上了。 常用hexo命令 常见命令 1234567hexo new "postName" #新建文章hexo new page "pageName" #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本 缩写： 1234hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 组合命令： 12hexo s -g #生成并本地预览hexo d -g #生成并上传 本文参考链接 https://www.jianshu.com/p/13f5e4d7099d http://theme-next.iissnan.com/theme-settings.html#rss https://www.jianshu.com/p/9f0e90cc32c2 https://www.simon96.online/2018/10/12/hexo-tutorial/ http://zwd596257180.gitee.io/blog/2019/04/15/hexo_manong_bog/ https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F10%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
